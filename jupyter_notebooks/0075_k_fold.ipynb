{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing between models with stratified k-fold validation\n",
    "\n",
    "In previous example we have used multiple random sampling in order to obtain a better measurement of accuracy for modes (repeating the model with different random training/test splits).\n",
    "\n",
    "A more robust method is to use 'stratified k-fold validation'. In this method the model is repeated k times, so that all the data is used once, but only once, as part of the test set. This, alone, is k-fold validation. Stratified k-fold validation adds an extra level of robustness by ensuring that in each of the k training/test splits, the balance of outcomes represents the balance of outcomes in the overall data set. Most commonly 10 different splits of the data are used.\n",
    "\n",
    "In this example we shall load up some data on treatment of acute stroke (data will be loaded from the internet). The model will try to predict whether patients are treated with a clot-busting drug. We will compare a number of different models using stratified k-fold validation.\n",
    "\n",
    "We set this up with the commands:\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    splits = 10\n",
    "    skf = StratifiedKFold(n_splits = splits)\n",
    "    skf.get_n_splits(X, y)\n",
    "\n",
    "And then we loop through the k splits with:\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 out of 10\n",
      "Split 2 out of 10\n",
      "Split 3 out of 10\n",
      "Split 4 out of 10\n",
      "Split 5 out of 10\n",
      "Split 6 out of 10\n",
      "Split 7 out of 10\n",
      "Split 8 out of 10\n",
      "Split 9 out of 10\n",
      "Split 10 out of 10\n",
      "\n",
      "Results Summary:\n",
      "                             Forest   SVM_lin   SVM_rbf        LR    Neural\n",
      "accuracy                   0.851946  0.839995  0.843081  0.839610  0.801859\n",
      "sensitivity                0.727978  0.767511  0.741951  0.753473  0.702353\n",
      "specificity                0.905567  0.871350  0.886804  0.876865  0.844867\n",
      "positive likelihood        8.799893  7.396559  7.384775  7.390298  4.909178\n",
      "negative likelihood        0.297522  0.263269  0.287613  0.276478  0.349459\n",
      "false positive rate        0.094433  0.128650  0.113196  0.123135  0.155133\n",
      "false negative rate        0.272022  0.232489  0.258049  0.246527  0.297647\n",
      "positive predictive value  0.775919  0.731363  0.747641  0.737093  0.669270\n",
      "negative predictive value  0.887152  0.898619  0.890479  0.894471  0.869677\n",
      "positive rate              0.285678  0.321505  0.302999  0.313414  0.320310\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Techniques applied:\n",
    "    1. Random Forests\n",
    "    2. Support Vector Machine (linear and rbf kernel)\n",
    "    3. Logistic Regression\n",
    "    4. Neural Network\n",
    "\"\"\"\n",
    "\n",
    "# %% Load modules\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# %% Function to calculate sensitivity ans specificty\n",
    "def calculate_diagnostic_performance(actual_predicted):\n",
    "    \"\"\" Calculate sensitivty and specificty.\n",
    "    Takes a Numpy array of 1 and zero, two columns: actual and predicted\n",
    "    Returns a tuple of results:\n",
    "    1) accuracy: proportion of test results that are correct    \n",
    "    2) sensitivity: proportion of true +ve identified\n",
    "    3) specificity: proportion of true -ve identified\n",
    "    4) positive likelihood: increased probability of true +ve if test +ve\n",
    "    5) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    6) false positive rate: proportion of false +ves in true -ve patients\n",
    "    7) false negative rate:  proportion of false -ves in true +ve patients\n",
    "    8) positive predictive value: chance of true +ve if test +ve\n",
    "    9) negative predictive value: chance of true -ve if test -ve\n",
    "    10) Count of test positives\n",
    "\n",
    "    *false positive rate is the percentage of healthy individuals who \n",
    "    incorrectly receive a positive test result\n",
    "    * alse neagtive rate is the percentage of diseased individuals who \n",
    "    incorrectly receive a negative test result\n",
    "    \n",
    "    \"\"\"\n",
    "    actual_predicted = test_results.values\n",
    "    actual_positives = actual_predicted[:, 0] == 1\n",
    "    actual_negatives = actual_predicted[:, 0] == 0\n",
    "    test_positives = actual_predicted[:, 1] == 1\n",
    "    test_negatives = actual_predicted[:, 1] == 0\n",
    "    test_correct = actual_predicted[:, 0] == actual_predicted[:, 1]\n",
    "    accuracy = np.average(test_correct)\n",
    "    true_positives = actual_positives & test_positives\n",
    "    true_negatives = actual_negatives & test_negatives\n",
    "    sensitivity = np.sum(true_positives) / np.sum(actual_positives)\n",
    "    specificity = np.sum(true_negatives) / np.sum(actual_negatives)\n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    false_postive_rate = 1 - specificity\n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    positive_predictive_value = np.sum(true_positives) / np.sum(test_positives)\n",
    "    negative_predicitive_value = np.sum(true_negatives) / np.sum(test_negatives)\n",
    "    positive_rate = np.mean(actual_predicted[:,1])\n",
    "    return (accuracy, sensitivity, specificity, positive_likelihood,\n",
    "            negative_likelihood, false_postive_rate, false_negative_rate,\n",
    "            positive_predictive_value, negative_predicitive_value, \n",
    "            positive_rate)\n",
    "\n",
    "\n",
    "# %% Print diagnostics results\n",
    "def print_diagnostic_results(results):\n",
    "    # format all results to three decimal places\n",
    "    three_decimals = [\"%.3f\" % v for v in results]\n",
    "    print()\n",
    "    print('Diagnostic results')\n",
    "    print('  accuracy:\\t\\t\\t', three_decimals[0])\n",
    "    print('  sensitivity:\\t\\t\\t', three_decimals[1])\n",
    "    print('  specificity:\\t\\t\\t', three_decimals[2])\n",
    "    print('  positive likelyhood:\\t\\t', three_decimals[3])\n",
    "    print('  negative likelyhood:\\t\\t', three_decimals[4])\n",
    "    print('  false positive rate:\\t\\t', three_decimals[5])\n",
    "    print('  false negative rate:\\t\\t', three_decimals[6])\n",
    "    print('  positive predictive value:\\t', three_decimals[7])\n",
    "    print('  negative predicitve value:\\t', three_decimals[8])\n",
    "    print()\n",
    "\n",
    "\n",
    "# %% Calculate weights from weights ratio:\n",
    "# Set up class weighting to bias for sensiitivty vs. specificity\n",
    "# Higher values increase sensitivity at the cost of specificity\n",
    "def calculate_class_weights(positive_class_weight_ratio):\n",
    "    positive_weight = ( positive_class_weight_ratio / \n",
    "                       (1 + positive_class_weight_ratio))\n",
    "    \n",
    "    negative_weight = 1 - positive_weight\n",
    "    class_weights = {0: negative_weight, 1: positive_weight}\n",
    "    return (class_weights)\n",
    "\n",
    "#%% Create results folder if needed\n",
    "# (Not used in this demo)   \n",
    "# OUTPUT_LOCATION = 'results'\n",
    "# if not os.path.exists(OUTPUT_LOCATION):\n",
    "#    os.makedirs(OUTPUT_LOCATION)\n",
    "    \n",
    "# %% Import data\n",
    "url = (\"https://raw.githubusercontent.com/MichaelAllen1966/wordpress_blog\" +\n",
    "       \"/master/jupyter_notebooks/stroke.csv\")\n",
    "df_stroke = pd.read_csv(url)\n",
    "feat_labels = list(df_stroke)[1:]\n",
    "number_of_features = len(feat_labels)\n",
    "X, y = df_stroke.iloc[:, 1:].values, df_stroke.iloc[:, 0].values\n",
    "\n",
    "# Set different weights for pisitive and negative results in SVM is required\n",
    "# This will adjust balance between sensitivity and specificity\n",
    "# For equal weighting, set at 1\n",
    "positive_class_weight_ratio = 1\n",
    "class_weights = calculate_class_weights(positive_class_weight_ratio)\n",
    "\n",
    "# Set up strtified k-fold\n",
    "splits = 10\n",
    "skf = StratifiedKFold(n_splits = splits)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "# %% Set up results dataframes\n",
    "forest_results = np.zeros((splits, 10))\n",
    "forest_importance = np.zeros((splits, number_of_features))\n",
    "svm_results_linear = np.zeros((splits, 10))\n",
    "svm_results_rbf = np.zeros((splits, 10))\n",
    "lr_results = np.zeros((splits, 10))\n",
    "nn_results = np.zeros((splits, 10))\n",
    "\n",
    "# %% Loop through the k splits of training/test data\n",
    "loop_count = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    print ('Split', loop_count + 1, 'out of', splits)\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    sc = StandardScaler()  # new Standard Scalar object\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    combined_results = pd.DataFrame()\n",
    "\n",
    "    # %% Random forests\n",
    "    forest = RandomForestClassifier(n_estimators=1000, n_jobs=-1, \n",
    "                                    class_weight='balanced')\n",
    "    forest.fit(X_train, y_train)\n",
    "    forest_importance[loop_count, :] = forest.feature_importances_\n",
    "    y_pred = forest.predict(X_test)\n",
    "    test_results = pd.DataFrame(np.vstack((y_test, y_pred)).T)\n",
    "    diagnostic_performance = (calculate_diagnostic_performance\n",
    "                              (test_results.values))\n",
    "    forest_results[loop_count, :] = diagnostic_performance\n",
    "    combined_results['Forest'] = y_pred\n",
    "\n",
    "    # %% SVM (Support Vector Machine) Linear\n",
    "    svm = SVC(kernel='linear', C=1.0, class_weight=class_weights)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    y_pred = svm.predict(X_test_std)\n",
    "    test_results = pd.DataFrame(np.vstack((y_test, y_pred)).T)\n",
    "    diagnostic_performance = (calculate_diagnostic_performance\n",
    "                              (test_results.values))\n",
    "    svm_results_linear[loop_count, :] = diagnostic_performance\n",
    "    combined_results['SVM_linear'] = y_pred\n",
    "\n",
    "    # %% SVM (Support Vector Machine) RBF\n",
    "    svm = SVC(kernel='rbf', C=1.0)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    y_pred = svm.predict(X_test_std)\n",
    "    test_results = pd.DataFrame(np.vstack((y_test, y_pred)).T)\n",
    "    diagnostic_performance = (calculate_diagnostic_performance\n",
    "                              (test_results.values))\n",
    "    svm_results_rbf[loop_count, :] = diagnostic_performance\n",
    "    combined_results['SVM_rbf'] = y_pred\n",
    "\n",
    "    # %% Logistic Regression\n",
    "    lr = LogisticRegression(C=100, class_weight=class_weights)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "    test_results = pd.DataFrame(np.vstack((y_test, y_pred)).T)\n",
    "    diagnostic_performance = (calculate_diagnostic_performance\n",
    "                              (test_results.values))\n",
    "    lr_results[loop_count, :] = diagnostic_performance\n",
    "    combined_results['LR'] = y_pred\n",
    "\n",
    "    # %% Neural Network\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-8, hidden_layer_sizes=(50, 5),\n",
    "                        max_iter=100000, shuffle=True, learning_rate_init=0.001,\n",
    "                        activation='relu', learning_rate='constant', tol=1e-7)\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    y_pred = clf.predict(X_test_std)\n",
    "    test_results = pd.DataFrame(np.vstack((y_test, y_pred)).T)\n",
    "    diagnostic_performance = (calculate_diagnostic_performance\n",
    "                              (test_results.values))\n",
    "    nn_results[loop_count, :] = diagnostic_performance\n",
    "    combined_results['NN'] = y_pred\n",
    "    \n",
    "    # Increment loop count\n",
    "    loop_count += 1\n",
    "\n",
    "# %% Transfer results to Pandas arrays\n",
    "results_summary = pd.DataFrame()\n",
    "\n",
    "results_column_names = (['accuracy', 'sensitivity', \n",
    "                         'specificity',\n",
    "                         'positive likelihood', \n",
    "                         'negative likelihood', \n",
    "                         'false positive rate', \n",
    "                         'false negative rate',\n",
    "                         'positive predictive value',\n",
    "                         'negative predictive value', \n",
    "                         'positive rate'])\n",
    "\n",
    "forest_results_df = pd.DataFrame(forest_results)\n",
    "forest_results_df.columns = results_column_names\n",
    "forest_importance_df = pd.DataFrame(forest_importance)\n",
    "forest_importance_df.columns = feat_labels\n",
    "results_summary['Forest'] = forest_results_df.mean()\n",
    "\n",
    "svm_results_lin_df = pd.DataFrame(svm_results_linear)\n",
    "svm_results_lin_df.columns = results_column_names\n",
    "results_summary['SVM_lin'] = svm_results_lin_df.mean()\n",
    "\n",
    "svm_results_rbf_df = pd.DataFrame(svm_results_rbf)\n",
    "svm_results_rbf_df.columns = results_column_names\n",
    "results_summary['SVM_rbf'] = svm_results_rbf_df.mean()\n",
    "\n",
    "lr_results_df = pd.DataFrame(lr_results)\n",
    "lr_results_df.columns = results_column_names\n",
    "results_summary['LR'] = lr_results_df.mean()\n",
    "\n",
    "nn_results_df = pd.DataFrame(nn_results)\n",
    "nn_results_df.columns = results_column_names\n",
    "results_summary['Neural'] = nn_results_df.mean()\n",
    "\n",
    "\n",
    "# %% Print summary results\n",
    "print()\n",
    "print('Results Summary:')\n",
    "print(results_summary)\n",
    "\n",
    "# %% Save files\n",
    "# NOT USED IN THIS DEMO\n",
    "# forest_results_df.to_csv('results/forest_results.csv')\n",
    "# forest_importance_df.to_csv('results/forest_importance.csv')\n",
    "# svm_results_lin_df.to_csv('results/svm_lin_results.csv')\n",
    "# svm_results_rbf_df.to_csv('results/svm_rbf_results.csv')\n",
    "# lr_results_df.to_csv('results/logistic_results.csv')\n",
    "# nn_results_df.to_csv('results/neural_network_results.csv')\n",
    "# results_summary.to_csv('results/results_summary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
